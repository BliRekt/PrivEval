{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from synthesis.synthesizers.privbayes import PrivBayes\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from Metrics import All_synthcity\n",
    "from Metrics import AttributeInference1 as AIR\n",
    "from Metrics import CGeneralizedCAP as GCAP\n",
    "from Metrics import CZeroCAP as CZCAP\n",
    "from Metrics import NNAA\n",
    "from Metrics import MemInf as MIR\n",
    "from Metrics import Hitting_rate\n",
    "from Metrics import MDCR\n",
    "from Metrics import DCR\n",
    "from Metrics import NNDR\n",
    "from Metrics import Hidden_rate\n",
    "from DataSynthesizer1.DataDescriber import DataDescriber\n",
    "from DataSynthesizer1.DataGenerator import DataGenerator\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Real dataset generation definition\n",
    "\n",
    "def generate_real_data(num_samples):\n",
    "    name_gen = Faker()\n",
    "    heights = np.around(list(np.random.normal(loc=170, scale=10, size=num_samples)), 2)\n",
    "    classic_icecreams = [\n",
    "        \"Vanilla\", \"Chocolate\", \"Strawberry\", \"Mint Chocolate Chip\",\n",
    "        \"Cookies and Cream\", \"Rocky Road\", \"Butter Pecan\", \"Neapolitan\",\n",
    "        \"Pistachio\", \"French Vanilla\"\n",
    "    ]\n",
    "    fav_icecream = list(random.choices(classic_icecreams, k=num_samples))\n",
    "\n",
    "    # Generate random first and last names\n",
    "    name_df = pd.DataFrame({\n",
    "        'First Name': [name_gen.first_name() for _ in range(num_samples)],\n",
    "        'Last Name': [name_gen.last_name() for _ in range(num_samples)]\n",
    "    })\n",
    "    height_df = pd.DataFrame({'Height': heights})\n",
    "    icecream_df = pd.DataFrame({'Flavour': fav_icecream})\n",
    "    basic_df = pd.concat([name_df, height_df, icecream_df], axis=1)\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Define country list and correlation rules\n",
    "    countries = [\"USA\", \"Canada\", \"Germany\", \"France\", \"Italy\", \"China\", \"Brazil\", \"Australia\", \"Japan\", \"UK\", \"Sweden\", \"Norway\", \"Denmark\", \"Finland\"]\n",
    "\n",
    "    # Ice cream preferences (default: random choice)\n",
    "    ice_creams = [\"Vanilla\", \"Chocolate\", \"Strawberry\", \"Mint\", \"Pistachio\", \"Stracciatella\"]\n",
    "\n",
    "    # Generate data\n",
    "    data = []\n",
    "    for i in range(num_samples):\n",
    "        person = {}\n",
    "\n",
    "        # Assign country\n",
    "        person[\"Country of Origin\"] = random.choice(countries)\n",
    "\n",
    "        # Assign favorite ice cream with correlation (Italy → Stracciatella preference)\n",
    "        if person[\"Country of Origin\"] == \"Italy\":\n",
    "            person[\"Favorite Icecream\"] = np.random.choice(ice_creams, p=[0.1, 0.1, 0.1, 0.1, 0.2, 0.4])\n",
    "        else:\n",
    "            person[\"Favorite Icecream\"] = random.choice(ice_creams)\n",
    "\n",
    "        # Assign liking for liquorice (Nordic countries → Higher probability)\n",
    "        if person[\"Country of Origin\"] in [\"Sweden\", \"Norway\", \"Denmark\", \"Finland\"]:\n",
    "            person[\"Like Liquorice\"] = np.random.choice([1, 0], p=[0.9, 0.1])  # 70% chance for Nordic countries\n",
    "        else:\n",
    "            person[\"Like Liquorice\"] = np.random.choice([1, 0], p=[0.2, 0.8])  # 20% for others\n",
    "\n",
    "        # Assign number of times visited Italy (Random integer, but higher if from Europe)\n",
    "        if person[\"Country of Origin\"] in [\"Germany\", \"France\", \"UK\", \"Sweden\", \"Norway\", \"Denmark\", \"Finland\", \"Italy\"]:\n",
    "            person[\"Times Visited Italy\"] = np.random.poisson(2)  # Higher average visits\n",
    "        else:\n",
    "            person[\"Times Visited Italy\"] = np.random.poisson(0.5)  # Lower average visits\n",
    "\n",
    "        # First time in London (UK residents more likely to say yes)\n",
    "        person[\"First Time London\"] = 1 if person[\"Country of Origin\"] == \"UK\" else np.random.choice([1, 0], p=[0.2, 0.8])\n",
    "\n",
    "        # Number of steps per day (Normal distribution with realistic values)\n",
    "        person[\"Steps per Day\"] = max(1000, int(np.random.normal(8000, 3000)))  # Avoids negative steps\n",
    "\n",
    "        data.append(person)\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    full_df = pd.concat([basic_df, df], axis=1)\n",
    "    \n",
    "    return full_df\n",
    "\n",
    "num_samples = 1500\n",
    "\n",
    "real_data = generate_real_data(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Synthesize dataset with 2 different methods\n",
    "def synthesize_no_bin(real_data, eps):    \n",
    "    # instantiate and fit synthesizer\n",
    "    pb = PrivBayes(epsilon=eps, verbose=False)\n",
    "    pb.fit(real_data)\n",
    "\n",
    "    # Synthesize data\n",
    "    gen_data  = pb.sample()\n",
    "\n",
    "    # Save to csv file\n",
    "    result = pd.DataFrame(gen_data.values, columns=gen_data.columns, index=range(real_data.shape[0]))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def synthesize_bin(real_data, eps):\n",
    "    real_data['Height'] = real_data['Height'].astype(float)\n",
    "    fn_encoder = LabelEncoder()\n",
    "    ln_encoder = LabelEncoder()\n",
    "    fl_encoder = LabelEncoder()\n",
    "    na_encoder = LabelEncoder()\n",
    "    r_fn = fn_encoder.fit_transform(real_data['First Name'])\n",
    "    r_ln = ln_encoder.fit_transform(real_data['Last Name'])\n",
    "    r_na = na_encoder.fit_transform(real_data['Nationality'])\n",
    "    r_fl = fl_encoder.fit_transform(real_data['Favorite Icecream'])\n",
    "    all_labels = pd.DataFrame({'First Name':r_fn, 'Last Name': r_ln, 'Height': real_data['Height'],'Nationality': r_na, 'Favorite Icecream':r_fl, 'Like Liquorice': real_data['Like Liquorice'], 'Times Been to Italy': real_data['Times Been to Italy'], 'First Time London': real_data['First Time London'], 'Steps per Day': real_data['Steps per Day']})\n",
    "    \n",
    "    describer = DataDescriber()\n",
    "    timestamp = datetime.now().timestamp()\n",
    "    all_labels.to_csv(f'{timestamp}.csv', index=False)\n",
    "    describer.describe_dataset_in_correlated_attribute_mode(dataset_file=f'{timestamp}.csv', \n",
    "                                                            epsilon=eps, \n",
    "                                                            k=2,\n",
    "                                                            attribute_to_is_candidate_key={\"First Name\": False, \"Last Name\": False, \"Height\": False, \"Nationality\": False, \"Favorite Icecream\": False, \"Like Liquorice\": False, \"Times Been to Italy\": False, \"First Time London\": False, \"Steps per Day\": False},\n",
    "                                                            attribute_to_datatype={\"First_Name\": \"Integer\", \"Last_Name\": \"Integer\", \"Height\": \"Float\", \"Nationality\": \"Integer\",\"Favorite Icecream\": \"Integer\",\"Like Liquorice\": \"Integer\",\"Times Been to Italy\": \"Integer\", \"First Time London\": \"Integer\",\"Steps per Day\": \"Integer\"},\n",
    "                                                            attribute_to_is_categorical={'First_Name': True, 'Last_Name': True, 'Height': False, \"Nationality\": True, \"Favorite Icecream\": True,\"Like Liquorice\": True,\"Times Been to Italy\": True, \"First Time London\": True,\"Steps per Day\": False},\n",
    "                                                            )\n",
    "    description = f'{timestamp}.json'\n",
    "    syn_path = f'syn_{timestamp}.csv'\n",
    "    describer.save_dataset_description_to_file(description)\n",
    "    generator = DataGenerator()\n",
    "    generator.generate_dataset_in_correlated_attribute_mode(n=len(all_labels), description_file=description, seed=timestamp)\n",
    "    generator.save_synthetic_data(syn_path)\n",
    "    result = pd.read_csv(syn_path, index_col=False).round(2)\n",
    "    os.remove(f'{timestamp}.csv')\n",
    "    os.remove(f'{timestamp}.json')\n",
    "    os.remove(f'syn_{timestamp}.csv')\n",
    "    result['First Name'] = fn_encoder.inverse_transform(result['First Name'].astype(int))\n",
    "    result['Last Name'] = ln_encoder.inverse_transform(result['Last Name'].astype(int))\n",
    "    result['Nationality'] = na_encoder.inverse_transform(result['Nationality'].astype(int))\n",
    "    result['Favorite Icecream'] = fl_encoder.inverse_transform(result['Favorite Icecream'].astype(int))\n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    eps_list = [0.02, 0.05, 0.1, 0.2, 0.5, 1, 2.5, 5]\n",
    "    for eps in eps_list:\n",
    "        synthesize_no_bin(real_data, eps).to_csv(f\"demo_syn/syn_bin_{eps}.csv\")\n",
    "        synthesize_bin(real_data, eps).to_csv(f\"demo_syn_new/syn_no_{eps}.csv\", index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get metric results\n",
    "def get_metric_results(real_data, syn_data):\n",
    "    real_data['Height'].astype('Float32')\n",
    "    syn_data['Height'].astype('Float32')\n",
    "\n",
    "    all_data = pd.concat([real_data, syn_data])\n",
    "    fn_encoder = LabelEncoder()\n",
    "    ln_encoder = LabelEncoder()\n",
    "    fl_encoder = LabelEncoder()\n",
    "    na_encoder = LabelEncoder()\n",
    "    r_fn = fn_encoder.fit_transform(all_data['First Name'])\n",
    "    r_ln = ln_encoder.fit_transform(all_data['Last Name'])\n",
    "    r_na = na_encoder.fit_transform(all_data['Nationality'])\n",
    "    r_fl = fl_encoder.fit_transform(all_data['Favorite Icecream'])\n",
    "    all_labels = pd.DataFrame({'First Name':r_fn, 'Last Name': r_ln, 'Height': all_data['Height'],'Nationality': r_na, 'Favorite Icecream':r_fl, 'Like Liquorice': all_data['Like Liquorice'], 'Times Been to Italy': all_data['Times Been to Italy'], 'First Time London': all_data['First Time London'], 'Steps per Day': all_data['Steps per Day']})\n",
    "    real_labels = all_labels[:len(real_data)]\n",
    "    syn_labels = all_labels[-len(real_data):]\n",
    "    \n",
    "    metrics = {\n",
    "                    'sanity': ['common_rows_proportion', 'nearest_syn_neighbor_distance', 'close_values_probability', 'distant_values_probability'],\n",
    "                    'stats': ['alpha_precision'],\n",
    "                    'detection': ['detection_mlp'],\n",
    "                    'privacy': ['identifiability_score'],\n",
    "                }\n",
    "    \n",
    "    synthcity_results = All_synthcity.calculate_metric(args = None, _real_data=real_data, _synthetic=real_data, _metrics=metrics)\n",
    "    crp = synthcity_results['mean'][1]\n",
    "    nsnd = 1-synthcity_results['mean'][2]\n",
    "    cvp = synthcity_results['mean'][3]\n",
    "    dvp = 1-synthcity_results['mean'][4]\n",
    "    auth = synthcity_results['mean'][10]\n",
    "    mlp = synthcity_results['mean'][11]\n",
    "    id_score = synthcity_results['mean'][12]\n",
    "    air = AIR.calculate_metric(args = None, _real_data=real_data, _synthetic=syn_data)\n",
    "    gcap = GCAP.calculate_metric(args = None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    zcap = CZCAP.calculate_metric(args = None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    mdcr = MDCR.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    hitR = Hitting_rate.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    mir = MIR.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    nnaa = NNAA.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    dcr = DCR.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    nndr = NNDR.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    hidd = Hidden_rate.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "     \n",
    "    priv_results = np.around([air, gcap, zcap, \n",
    "                            mdcr, hitR, mir, \n",
    "                            nnaa, crp, nsnd, \n",
    "                            cvp, dvp, auth, \n",
    "                            mlp, id_score, \n",
    "                            dcr, nndr, hidd\n",
    "                            ], 2).tolist()\n",
    "    \n",
    "    metric_list = [\"Attribute Inference Risk\", \"GeneralizedCAP\", \"ZeroCAP\", \n",
    "                   \"Median Distance to Closest Record\", \"Hitting Rate\",\n",
    "                   \"Membership Inference Risk\", \"Nearest Neighbour Adversarial Accuracy\",\n",
    "                   \"Common Row Proportion\", \"Nearest Synthetic Neighbour Distance\",\n",
    "                   \"Close Value Probability\", \"Distant Value Probability\",\n",
    "                   \"Authenticity\", \"DetectionMLP\", \"Identifiability Score\"\n",
    "                   , \"Distance to Closest Record\", \"Nearest Neighbour Distance Ratio\", \"Hidden Rate\"\n",
    "                   ]\n",
    "    \n",
    "    results = pd.DataFrame({'Metric':metric_list, 'Result':priv_results})\n",
    "    \n",
    "    return results\n",
    "\n",
    "eps_list = [0.02, 0.05, 0.1, 0.2, 0.5, 1, 2.5, 5]\n",
    "\n",
    "for eps in eps_list:\n",
    "    syn_no = pd.read_csv(f\"demo_syn/syn_no_{eps}.csv\")\n",
    "    syn_bin = pd.read_csv(f\"demo_syn/syn_bin_{eps}.csv\")\n",
    "    get_metric_results(real_data, syn_no).to_csv(f\"metric_results/syn_bin_{eps}.csv\")\n",
    "    get_metric_results(real_data, syn_bin).to_csv(f\"metric_results/syn_no_{eps}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
