{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "#Code for generating a baby dataset\n",
    "\n",
    "\n",
    "\n",
    "name_gen = Faker()\n",
    "num_samples = 9\n",
    "\n",
    "height = list(np.random.normal(loc=50, scale=1, size=num_samples))\n",
    "\n",
    "classic_icecreams = [\n",
    "    \"Vanilla\", \"Chocolate\", \"Strawberry\", \"Mint Chocolate Chip\",\n",
    "    \"Cookies and Cream\", \"Rocky Road\", \"Butter Pecan\", \"Neapolitan\",\n",
    "    \"Pistachio\", \"French Vanilla\"\n",
    "]\n",
    "\n",
    "fav_icecream = list(random.choices(classic_icecreams, k=num_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random first and last names\n",
    "name_df = pd.DataFrame({\n",
    "    'First_Name': [name_gen.first_name() for _ in range(num_samples)],\n",
    "    'Last_Name': [name_gen.last_name() for _ in range(num_samples)]\n",
    "})\n",
    "\n",
    "height_df = pd.DataFrame({'Height': height})\n",
    "\n",
    "icecream_df = pd.DataFrame({'Flavour': fav_icecream})\n",
    "\n",
    "full_df = pd.concat([name_df, height_df, icecream_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from saiph.projection import fit_transform\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sens_individual = ['John', 'Davies', 182.5, 'Vanilla']\n",
    "new_individual_df = pd.DataFrame([sens_individual], columns=full_df.columns)\n",
    "all_individuals = pd.concat([full_df, new_individual_df], ignore_index=True)\n",
    "print(all_individuals)\n",
    "\n",
    "\n",
    "#PCA\n",
    "coord_real_pca, model_pca = fit_transform(all_individuals, nf=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a synthetic dataset\n",
    "from synthesis.synthesizers.privbayes import PrivBayes\n",
    "from saiph.projection import transform\n",
    "\n",
    "eps=np.inf\n",
    "epsilon = eps\n",
    "\n",
    "pb = PrivBayes(epsilon=epsilon, verbose=False)\n",
    "\n",
    "pb.fit(all_individuals)\n",
    "\n",
    "gen_data  = pb.sample()\n",
    "\n",
    "final_data = pd.DataFrame(gen_data.values, columns=gen_data.columns, index=range(all_individuals.shape[0]))\n",
    "\n",
    "print(final_data)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "def scatter_plot(coord_real, coord_synth):\n",
    "    # Scatter Plot\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot DataFrame 1\n",
    "    plt.scatter(coord_real['Dim. 1'], coord_real['Dim. 2'], color='blue', label='Real', alpha=0.7)\n",
    "\n",
    "    # Plot DataFrame 2\n",
    "    plt.scatter(coord_synth['Dim. 1'], coord_synth['Dim. 2'], color='red', label='Synthetic', alpha=0.5)\n",
    "\n",
    "    plt.title('Scatter Plot of real and synthetic data')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Show Plot\n",
    "    plt.show()\n",
    "\n",
    "#PCA\n",
    "syn_coords_pca = transform(final_data, model_pca)\n",
    "scatter_plot(coord_real_pca, syn_coords_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list = [0.02, 0.05, 0.1, 0.2, 0.5, 1, 2.5, 5]\n",
    "for liquorice in [0,1]:\n",
    "    real_dir = f'sample_data_{liquorice}.csv'\n",
    "    real_data = pd.read_csv(real_dir)\n",
    "    for eps in eps_list:\n",
    "        #synthesize_no_bin(real_data, eps).to_csv(f\"demo_syn/syn_bin_{liquorice}_{eps}.csv\")\n",
    "        syn = pd.read_csv(f\"demo_syn_new/syn_no_{liquorice}_{eps}.csv\")\n",
    "        intersection = (\n",
    "            real_data.merge(syn, how=\"inner\", indicator=False).drop_duplicates()\n",
    "        )\n",
    "        print(len(intersection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scatter_plot_tsne(coord_real, coord_synth):\n",
    "    real = pd.DataFrame(coord_real)\n",
    "    syn = pd.DataFrame(coord_synth)\n",
    "    coords = pd.merge(real, syn)\n",
    "    # Scatter Plot\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot DataFrame 1\n",
    "    plt.scatter(real[0], real[1], color='blue', label='Real', alpha=0.5)\n",
    "\n",
    "    # Plot DataFrame 2\n",
    "    plt.scatter(syn[0], syn[1], color='red', label='Synthetic', alpha=0.5)\n",
    "\n",
    "    plt.title('Scatter Plot of real and synthetic data')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Show Plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "\n",
    "tsne_coord_real = tsne.fit_transform(all_individuals)\n",
    "\n",
    "tsne_coord_syn = tsne.fit_transform(final_data)\n",
    "\n",
    "scatter_plot_tsne(tsne_coord_real, tsne_coord_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from saiph.projection import fit_transform\n",
    "from saiph.projection import transform\n",
    "\n",
    "def scatter_plot(coord_real, coord_synth):\n",
    "    # Scatter Plot\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot DataFrame 1\n",
    "    plt.scatter(coord_real['Dim. 1'], coord_real['Dim. 2'], color='blue', label='Real', alpha=0.7)\n",
    "\n",
    "    # Plot DataFrame 2\n",
    "    plt.scatter(coord_synth['Dim. 1'], coord_synth['Dim. 2'], color='red', label='Synthetic', alpha=0.5)\n",
    "\n",
    "    plt.title('Scatter Plot of real and synthetic data')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Show Plot\n",
    "    plt.show()\n",
    "    \n",
    "pca_coord_real, model = fit_transform(all_individuals, nf=2)\n",
    "pca_coord_syn = transform(final_data, model)\n",
    "\n",
    "scatter_plot(pca_coord_real, pca_coord_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With label encoding\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from DataSynthesizer1.DataDescriber import DataDescriber\n",
    "from DataSynthesizer1.DataGenerator import DataGenerator\n",
    "from synthesis.synthesizers.privbayes import PrivBayes\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def generate_real_data(num_samples, liquorice):\n",
    "    #Code for generating a baby dataset\n",
    "    name_gen = Faker()\n",
    "    heights = np.around(list(np.random.normal(loc=170, scale=10, size=num_samples)), 2)\n",
    "    \n",
    "\n",
    "    # Generate random first and last names\n",
    "    name_df = pd.DataFrame({\n",
    "        'First_Name': [name_gen.first_name() for _ in range(num_samples)],\n",
    "        'Last_Name': [name_gen.last_name() for _ in range(num_samples)]\n",
    "    })\n",
    "    height_df = pd.DataFrame({'Height': heights})\n",
    "    basic_df = pd.concat([name_df, height_df], axis=1)\n",
    "\n",
    "    # Define country list and correlation rules\n",
    "    countries = [\"USA\", \"Canada\", \"Germany\", \"France\", \"Italy\", \"China\", \"Brazil\", \"Australia\", \"Japan\", \"UK\", \"Sweden\", \"Norway\", \"Denmark\", \"Finland\"]\n",
    "\n",
    "    # Ice cream preferences (default: random choice)\n",
    "    ice_creams = [\"Vanilla\", \"Chocolate\", \"Strawberry\", \"Mint\", \"Pistachio\", \"Stracciatella\"]\n",
    "\n",
    "    # Generate data\n",
    "    data = []\n",
    "    for i in range(num_samples):\n",
    "        person = {}\n",
    "\n",
    "        # Assign country\n",
    "        person[\"Country of Origin\"] = random.choice(countries)\n",
    "\n",
    "        # Assign favorite ice cream with correlation (Italy → Stracciatella preference)\n",
    "        if person[\"Country of Origin\"] == \"Italy\":\n",
    "            person[\"Favorite Ice Cream\"] = np.random.choice(ice_creams, p=[0.1, 0.1, 0.1, 0.1, 0.2, 0.4])\n",
    "        else:\n",
    "            person[\"Favorite Ice Cream\"] = random.choice(ice_creams)\n",
    "\n",
    "        # Assign liking for liquorice (Nordic countries → Higher probability)\n",
    "        if person[\"Country of Origin\"] in [\"Sweden\", \"Norway\", \"Denmark\", \"Finland\"]:\n",
    "            person[\"Likes Liquorice\"] = np.random.choice([1, 0], p=[0.9, 0.1])  # 70% chance for Nordic countries\n",
    "        else:\n",
    "            person[\"Likes Liquorice\"] = np.random.choice([1, 0], p=[0.2, 0.8])  # 20% for others\n",
    "\n",
    "        # Assign number of times visited Italy (Random integer, but higher if from Europe)\n",
    "        if person[\"Country of Origin\"] in [\"Germany\", \"France\", \"UK\", \"Sweden\", \"Norway\", \"Denmark\", \"Finland\", \"Italy\"]:\n",
    "            person[\"Times Visited Italy\"] = np.random.poisson(2)  # Higher average visits\n",
    "        else:\n",
    "            person[\"Times Visited Italy\"] = np.random.poisson(0.5)  # Lower average visits\n",
    "\n",
    "        # First time in London (UK residents more likely to say yes)\n",
    "        person[\"First Time in London\"] = 1 if person[\"Country of Origin\"] == \"UK\" else np.random.choice([1, 0], p=[0.2, 0.8])\n",
    "\n",
    "        # Number of steps per day (Normal distribution with realistic values)\n",
    "        person[\"Steps per Day\"] = max(1000, int(np.random.normal(8000, 3000)))  # Avoids negative steps\n",
    "\n",
    "        data.append(person)\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    full_df = pd.concat([basic_df, df], axis=1, ignore_index=True)\n",
    "    \n",
    "    if liquorice == 0:\n",
    "        # Sample row: UK resident who does NOT like liquorice\n",
    "        indiv = [\n",
    "            \"James\", \"Smith\", round(random.gauss(175, 10), 2), \"UK\", \"Strawberry\", 0, 2, 0, 7500\n",
    "        ]\n",
    "        indiv_df = pd.DataFrame([indiv], columns=full_df.columns)\n",
    "    if liquorice == 1:\n",
    "        # Sample row: Sweden resident who LIKES liquorice\n",
    "        indiv = [\n",
    "            \"Lars\", \"Andersson\", round(random.gauss(185, 10), 2), \"Sweden\", \"Chocolate\", 1, 3, 0, 9200 \n",
    "        ]\n",
    "        indiv_df = pd.DataFrame([indiv], columns=full_df.columns)\n",
    "    full_df = pd.concat([full_df, indiv_df], ignore_index=True)\n",
    "    full_df.columns = [\"First Name\", \"Last Name\", \"Height\", \"Nationality\", \"Favorite Icecream\", \"Like Liquorice\", \"Times Been to Italy\", \"First Time London\", \"Steps per Day\"]\n",
    "    print(full_df)\n",
    "    # Save to CSV (optional)\n",
    "    full_df.to_csv(f\"sample_data_{liquorice}.csv\", index=False)\n",
    "\n",
    "def synthesize_no_bin(real_data, eps):    \n",
    "    # instantiate and fit synthesizer\n",
    "    pb = PrivBayes(epsilon=eps, verbose=False)\n",
    "    pb.fit(real_data)\n",
    "\n",
    "    # Synthesize data\n",
    "    gen_data  = pb.sample()\n",
    "\n",
    "    # Save to csv file\n",
    "    result = pd.DataFrame(gen_data.values, columns=gen_data.columns, index=range(real_data.shape[0]))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def synthesize_bin(real_data, eps):\n",
    "    real_data['Height'] = real_data['Height'].astype(float)\n",
    "    fn_encoder = LabelEncoder()\n",
    "    ln_encoder = LabelEncoder()\n",
    "    fl_encoder = LabelEncoder()\n",
    "    na_encoder = LabelEncoder()\n",
    "    r_fn = fn_encoder.fit_transform(real_data['First Name'])\n",
    "    r_ln = ln_encoder.fit_transform(real_data['Last Name'])\n",
    "    r_na = na_encoder.fit_transform(real_data['Nationality'])\n",
    "    r_fl = fl_encoder.fit_transform(real_data['Favorite Icecream'])\n",
    "    all_labels = pd.DataFrame({'First Name':r_fn, 'Last Name': r_ln, 'Height': real_data['Height'],'Nationality': r_na, 'Favorite Icecream':r_fl, 'Like Liquorice': real_data['Like Liquorice'], 'Times Been to Italy': real_data['Times Been to Italy'], 'First Time London': real_data['First Time London'], 'Steps per Day': real_data['Steps per Day']})\n",
    "    \n",
    "    describer = DataDescriber()\n",
    "    timestamp = datetime.now().timestamp()\n",
    "    all_labels.to_csv(f'{timestamp}.csv', index=False)\n",
    "    describer.describe_dataset_in_correlated_attribute_mode(dataset_file=f'{timestamp}.csv', \n",
    "                                                            epsilon=eps, \n",
    "                                                            k=2,\n",
    "                                                            attribute_to_is_candidate_key={\"First Name\": False, \"Last Name\": False, \"Height\": False, \"Nationality\": False, \"Favorite Icecream\": False, \"Like Liquorice\": False, \"Times Been to Italy\": False, \"First Time London\": False, \"Steps per Day\": False},\n",
    "                                                            attribute_to_datatype={\"First_Name\": \"Integer\", \"Last_Name\": \"Integer\", \"Height\": \"Float\", \"Nationality\": \"Integer\",\"Favorite Icecream\": \"Integer\",\"Like Liquorice\": \"Integer\",\"Times Been to Italy\": \"Integer\", \"First Time London\": \"Integer\",\"Steps per Day\": \"Integer\"},\n",
    "                                                            attribute_to_is_categorical={'First_Name': True, 'Last_Name': True, 'Height': False, \"Nationality\": True, \"Favorite Icecream\": True,\"Like Liquorice\": True,\"Times Been to Italy\": True, \"First Time London\": True,\"Steps per Day\": False},\n",
    "                                                            )\n",
    "    description = f'{timestamp}.json'\n",
    "    syn_path = f'syn_{timestamp}.csv'\n",
    "    describer.save_dataset_description_to_file(description)\n",
    "    generator = DataGenerator()\n",
    "    generator.generate_dataset_in_correlated_attribute_mode(n=len(all_labels), description_file=description, seed=timestamp)\n",
    "    generator.save_synthetic_data(syn_path)\n",
    "    result = pd.read_csv(syn_path, index_col=False).round(2)\n",
    "    os.remove(f'{timestamp}.csv')\n",
    "    os.remove(f'{timestamp}.json')\n",
    "    os.remove(f'syn_{timestamp}.csv')\n",
    "    result['First Name'] = fn_encoder.inverse_transform(result['First Name'].astype(int))\n",
    "    result['Last Name'] = ln_encoder.inverse_transform(result['Last Name'].astype(int))\n",
    "    result['Nationality'] = na_encoder.inverse_transform(result['Nationality'].astype(int))\n",
    "    result['Favorite Icecream'] = fl_encoder.inverse_transform(result['Favorite Icecream'].astype(int))\n",
    "    return result\n",
    "\n",
    "    \n",
    "#generate_real_data(1499, 1)\n",
    "#generate_real_data(1499, 0)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    eps_list = [0.02, 0.05, 0.1, 0.2, 0.5, 1, 2.5, 5]\n",
    "    for liquorice in [0,1]:\n",
    "        real_dir = f'sample_data_{liquorice}.csv'\n",
    "        real_data = pd.read_csv(real_dir, index_col=False)\n",
    "        for eps in eps_list:\n",
    "            #synthesize_no_bin(real_data, eps).to_csv(f\"demo_syn/syn_bin_{liquorice}_{eps}.csv\")\n",
    "            synthesize_bin(real_data, eps).to_csv(f\"demo_syn_new/syn_no_{liquorice}_{eps}.csv\", index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Metrics import AttributeInference as AIR\n",
    "from Metrics import CGeneralizedCAP as GCAP\n",
    "from Metrics import CZeroCAP as CZCAP\n",
    "from Metrics import DCR\n",
    "from Metrics import NNDR\n",
    "from Metrics import Hidden_rate\n",
    "from Metrics import NNAA\n",
    "from Metrics import MemInf as MIR\n",
    "from Metrics import Hitting_rate\n",
    "from Metrics import MDCR\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from Metrics import All_synthcity\n",
    "import pandas as pd\n",
    "\n",
    "def get_metric_results(real_data, syn_data):\n",
    "    real_data['Height'].astype('Float32')\n",
    "    syn_data['Height'].astype('Float32')\n",
    "\n",
    "    all_data = pd.concat([real_data, syn_data])\n",
    "    fn_encoder = LabelEncoder()\n",
    "    ln_encoder = LabelEncoder()\n",
    "    fl_encoder = LabelEncoder()\n",
    "    na_encoder = LabelEncoder()\n",
    "    r_fn = fn_encoder.fit_transform(all_data['First Name'])\n",
    "    r_ln = ln_encoder.fit_transform(all_data['Last Name'])\n",
    "    r_na = na_encoder.fit_transform(all_data['Nationality'])\n",
    "    r_fl = fl_encoder.fit_transform(all_data['Favorite Icecream'])\n",
    "    all_labels = pd.DataFrame({'First Name':r_fn, 'Last Name': r_ln, 'Height': all_data['Height'],'Nationality': r_na, 'Favorite Icecream':r_fl, 'Like Liquorice': all_data['Like Liquorice'], 'Times Been to Italy': all_data['Times Been to Italy'], 'First Time London': all_data['First Time London'], 'Steps per Day': all_data['Steps per Day']})\n",
    "    real_labels = all_labels[:len(real_data)]\n",
    "    syn_labels = all_labels[-len(real_data):]\n",
    "    \n",
    "    metrics = {\n",
    "                    'sanity': ['common_rows_proportion', 'nearest_syn_neighbor_distance', 'close_values_probability', 'distant_values_probability'],\n",
    "                    'stats': ['alpha_precision'],\n",
    "                    'detection': ['detection_mlp'],\n",
    "                    'privacy': ['identifiability_score'],\n",
    "                }\n",
    "    #air = AIR.calculate_metric(args = None, _real_data=real_dat, _synthetic=syn_dat)\n",
    "    synthcity_results = All_synthcity.calculate_metric(args = None, _real_data=real_data, _synthetic=real_data, _metrics=metrics)\n",
    "    crp = synthcity_results['mean'][1]\n",
    "    nsnd = 1-synthcity_results['mean'][2]\n",
    "    cvp = synthcity_results['mean'][3]\n",
    "    dvp = 1-synthcity_results['mean'][4]\n",
    "    auth = synthcity_results['mean'][10]\n",
    "    mlp = synthcity_results['mean'][11]\n",
    "    id_score = synthcity_results['mean'][12]\n",
    "    air = AIR.calculate_metric(args = None, _real_data=real_data, _synthetic=syn_data)\n",
    "    gcap = GCAP.calculate_metric(args = None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    zcap = CZCAP.calculate_metric(args = None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    mdcr = MDCR.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    hitR = Hitting_rate.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    mir = MIR.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    nnaa = NNAA.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    #---These metrics simply take too long to run\n",
    "    dcr = DCR.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    nndr = NNDR.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    hidd = Hidden_rate.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "     \n",
    "    priv_results = np.around([air, gcap, zcap, \n",
    "                            mdcr, hitR, mir, \n",
    "                            nnaa, crp, nsnd, \n",
    "                            cvp, dvp, auth, \n",
    "                            mlp, id_score, \n",
    "                            dcr, nndr, hidd\n",
    "                            ], 2).tolist()\n",
    "    \n",
    "    metric_list = [\"Attribute Inference Risk\", \"GeneralizedCAP\", \"ZeroCAP\", \n",
    "                   \"Median Distance to Closest Record\", \"Hitting Rate\",\n",
    "                   \"Membership Inference Risk\", \"Nearest Neighbour Adversarial Accuracy\",\n",
    "                   \"Common Row Proportion\", \"Nearest Synthetic Neighbour Distance\",\n",
    "                   \"Close Value Probability\", \"Distant Value Probability\",\n",
    "                   \"Authenticity\", \"DetectionMLP\", \"Identifiability Score\"\n",
    "                   , \"Distance to Closest Record\", \"Nearest Neighbour Distance Ratio\", \"Hidden Rate\"\n",
    "                   ]\n",
    "    \n",
    "    results = pd.DataFrame({'Metric':metric_list, 'Result':priv_results})\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "eps_list = [0.02, 0.05, 0.1, 0.2, 0.5, 1, 2.5, 5]\n",
    "for liquorice in [0,1]:\n",
    "    real_dir = f'sample_data_{liquorice}.csv'\n",
    "    real_data = pd.read_csv(real_dir)\n",
    "    for eps in eps_list:\n",
    "        syn_no = pd.read_csv(f\"demo_syn/syn_no_{liquorice}_{eps}.csv\")\n",
    "        syn_bin = pd.read_csv(f\"demo_syn/syn_bin_{liquorice}_{eps}.csv\")\n",
    "        get_metric_results(real_data, syn_no).to_csv(f\"metric_results/syn_bin_{liquorice}_{eps}.csv\")\n",
    "        get_metric_results(real_data, syn_bin).to_csv(f\"metric_results/syn_no_{liquorice}_{eps}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Metrics import All_synthcity\n",
    "from Metrics import AttributeInference1 as AIR\n",
    "from Metrics import CGeneralizedCAP as GCAP\n",
    "from Metrics import CZeroCAP as CZCAP\n",
    "from Metrics import DCR\n",
    "from Metrics import NNDR\n",
    "from Metrics import Hidden_rate\n",
    "from Metrics import NNAA\n",
    "from Metrics import MemInf as MIR\n",
    "from Metrics import Hitting_rate\n",
    "from Metrics import MDCR\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from Metrics import All_synthcity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def get_metric_results(real_data, syn_data):\n",
    "    all_data = pd.concat([real_data, syn_data])\n",
    "    fn_encoder = LabelEncoder()\n",
    "    ln_encoder = LabelEncoder()\n",
    "    fl_encoder = LabelEncoder()\n",
    "    na_encoder = LabelEncoder()\n",
    "    r_fn = fn_encoder.fit_transform(all_data['First Name'])\n",
    "    r_ln = ln_encoder.fit_transform(all_data['Last Name'])\n",
    "    r_na = na_encoder.fit_transform(all_data['Nationality'])\n",
    "    r_fl = fl_encoder.fit_transform(all_data['Favorite Icecream'])\n",
    "    all_labels = pd.DataFrame({'First Name':r_fn, 'Last Name': r_ln, 'Height': all_data['Height'],'Nationality': r_na, 'Favorite Icecream':r_fl, 'Like Liquorice': all_data['Like Liquorice'], 'Times Been to Italy': all_data['Times Been to Italy'], 'First Time London': all_data['First Time London'], 'Steps per Day': all_data['Steps per Day']})\n",
    "    real_labels = all_labels[:len(real_data)]\n",
    "    syn_labels = all_labels[-len(real_data):]\n",
    "    \n",
    "    metrics = {\n",
    "                    'sanity': ['common_rows_proportion', 'nearest_syn_neighbor_distance', 'close_values_probability', 'distant_values_probability'],\n",
    "                    'stats': ['alpha_precision'],\n",
    "                    'detection': ['detection_mlp'],\n",
    "                    'privacy': ['identifiability_score'],\n",
    "                }\n",
    "    #air = AIR.calculate_metric(args = None, _real_data=real_data, _synthetic=syn_data)\n",
    "    # synthcity_results = All_synthcity.calculate_metric(args = None, _real_data=real_data, _synthetic=syn_data, _metrics=metrics)\n",
    "    # crp = synthcity_results['mean'][1]\n",
    "    # nsnd = 1-synthcity_results['mean'][2]\n",
    "    # cvp = synthcity_results['mean'][3]\n",
    "    # dvp = 1-synthcity_results['mean'][4]\n",
    "    # auth = synthcity_results['mean'][10]\n",
    "    # mlp = synthcity_results['mean'][11]\n",
    "    # id_score = synthcity_results['mean'][12]\n",
    "    #air = AIR.calculate_metric(args = None, _real_data=real_data, _synthetic=syn_data)\n",
    "    # gcap = GCAP.calculate_metric(args = None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    # zcap = CZCAP.calculate_metric(args = None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    # mdcr = MDCR.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    hitR = Hitting_rate.calculate_metric(args=None, _real_data=real_data, _synthetic=syn_data)\n",
    "    # mir = MIR.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    # nnaa = NNAA.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    #---These metrics simply take too long to run\n",
    "    # dcr = DCR.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    # nndr = NNDR.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    # hidd = Hidden_rate.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "     \n",
    "    priv_results = np.around([#air, gcap, zcap, \n",
    "                            #mdcr, \n",
    "                            hitR, \n",
    "                            # mir, \n",
    "                            #nnaa, \n",
    "                            #crp, nsnd, \n",
    "                            #cvp, dvp, auth, \n",
    "                            #mlp, id_score, \n",
    "                            #dcr, nndr, hidd\n",
    "                            ], 2).tolist()\n",
    "    \n",
    "    metric_list = [#\"Attribute Inference Riks\", \"GeneralizedCAP\", \"ZeroCAP\", \"Median Distance to Closest Record\", \n",
    "                   \"Hitting Rate\",\n",
    "                   #\"Membership Inference Risk\", \"Nearest Neighbour Adversarial Accuracy\",\n",
    "                   #\"Common Row Proportion\", \"Nearest Synthetic Neighbour Distance\",\n",
    "                   #\"Close Value Probability\", \"Distant Value Probability\",\n",
    "                   #\"Authenticity\", \"DetectionMLP\", \"Identifiability Score\"\n",
    "                   #, \"Distance to Closest Record\", \"Nearest Neighbour Distance Ratio\", \"Hidden Rate\"\n",
    "                   ]\n",
    "    \n",
    "    results = pd.DataFrame({'Metric':metric_list, 'Result':priv_results})\n",
    "    \n",
    "    return results\n",
    "    \n",
    "\n",
    "eps_list = [0.02, 0.05, 0.1, 0.2, 0.5, 1, 2.5, 5]\n",
    "for liquorice in [0,1]:\n",
    "    real_dir = f'sample_data_{liquorice}.csv'\n",
    "    real_data = pd.read_csv(real_dir, index_col=False)\n",
    "    for eps in eps_list:\n",
    "        syn_no = pd.read_csv(f\"demo_syn/syn_no_{liquorice}_{eps}.csv\", index_col=False).drop(columns=['Unnamed: 0'])\n",
    "        #syn_bin = pd.read_csv(f\"demo_syn/syn_bin_{liquorice}_{eps}.csv\")\n",
    "        #get_metric_results(real_data, syn_no).to_csv(f\"metric_full_new/syn_bin_{liquorice}_{eps}.csv\")\n",
    "        get_metric_results(real_data, syn_no).to_csv(f\"metric_full/syn_no_{liquorice}_{eps}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "eps_list = [0.02, 0.05, 0.1, 0.2, 0.5, 1, 2.5, 5]\n",
    "for liquorice in [0,1]:\n",
    "    for eps in eps_list:\n",
    "        syn_no = pd.read_csv(f\"metric_full_new/syn_no_{liquorice}_{eps}.csv\")\n",
    "        syn_bin = pd.read_csv(f\"metric_full_new/syn_bin_{liquorice}_{eps}.csv\")\n",
    "        syn_no_more = pd.read_csv(f\"metric_results/syn_no_{liquorice}_{eps}.csv\")\n",
    "        syn_bin_more = pd.read_csv(f\"metric_results/syn_bin_{liquorice}_{eps}.csv\")\n",
    "        # full_no_bin.to_csv(f\"metric_results/syn_no_{liquorice}_{eps}.csv\")\n",
    "        # full_bin.to_csv(f\"metric_results/syn_bin_{liquorice}_{eps}.csv\")\n",
    "        \n",
    "        syn_no_more[\"Metric\"] = syn_no_more[\"Metric\"].str.strip()\n",
    "        syn_no[\"Metric\"] = syn_no[\"Metric\"].str.strip()\n",
    "        result_map = dict(zip(syn_no[\"Metric\"], syn_no[\"Result\"]))\n",
    "        syn_no_more[\"Result\"] = syn_no_more[\"Metric\"].map(result_map).combine_first(syn_no_more[\"Result\"])\n",
    "        syn_no_more.drop(columns=['Unnamed: 0.1']).to_csv(f\"metric_results/syn_no_{liquorice}_{eps}.csv\")\n",
    "        \n",
    "        syn_bin_more[\"Metric\"] = syn_bin_more[\"Metric\"].str.strip()\n",
    "        syn_bin[\"Metric\"] = syn_bin[\"Metric\"].str.strip()\n",
    "        result_map = dict(zip(syn_bin[\"Metric\"], syn_bin[\"Result\"]))\n",
    "        syn_bin_more[\"Result\"] = syn_bin_more[\"Metric\"].map(result_map).combine_first(syn_bin_more[\"Result\"])\n",
    "        syn_bin_more.drop(columns=['Unnamed: 0.1']).to_csv(f\"metric_results/syn_bin_{liquorice}_{eps}.csv\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "eps_list = [0.02, 0.05, 0.1, 0.2, 0.5, 1, 2.5, 5]\n",
    "for liquorice in [0,1]:\n",
    "    for eps in eps_list:\n",
    "        syn_no = pd.read_csv(f\"metric_full_new/syn_no_{liquorice}_{eps}.csv\")\n",
    "        syn_no_more = pd.read_csv(f\"metric_full/syn_no_{liquorice}_{eps}.csv\")\n",
    "        all = pd.concat([syn_no_more, syn_no], axis=0)\n",
    "        all.to_csv(f\"metric_results/syn_no_{liquorice}_{eps}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list = [0.02, 0.05, 0.1, 0.2, 0.5, 1, 2.5, 5]\n",
    "for liquorice in [0,1]:\n",
    "    for eps in eps_list:\n",
    "        df1 = pd.read_csv(f\"metric_results/syn_no_{liquorice}_{eps}.csv\")\n",
    "        df2 = pd.read_csv(f\"metric_full/syn_no_{liquorice}_{eps}.csv\")\n",
    "        df1[\"Metric\"] = df1[\"Metric\"].str.strip()\n",
    "        df2[\"Metric\"] = df2[\"Metric\"].str.strip()\n",
    "\n",
    "        # Create a mapping from df2 (Metric → Result)\n",
    "        result_map = dict(zip(df2[\"Metric\"], df2[\"Result\"]))\n",
    "\n",
    "        # Replace df1's \"Result\" where Metric matches, keeping original values if no match is found\n",
    "        df1[\"Result\"] = df1[\"Metric\"].map(result_map).combine_first(df1[\"Result\"])\n",
    "        df1.to_csv(f\"metric_results/syn_no_{liquorice}_{eps}.csv\")\n",
    "        print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without labelencoding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from DataSynthesizer1.DataDescriber import DataDescriber\n",
    "from DataSynthesizer1.DataGenerator import DataGenerator\n",
    "from synthesis.synthesizers.privbayes import PrivBayes\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def generate_real_data(num_samples, liquorice):\n",
    "    #Code for generating a baby dataset\n",
    "    name_gen = Faker()\n",
    "    heights = np.around(list(np.random.normal(loc=170, scale=10, size=num_samples)), 2)\n",
    "    \n",
    "\n",
    "    # Generate random first and last names\n",
    "    name_df = pd.DataFrame({\n",
    "        'First_Name': [name_gen.first_name() for _ in range(num_samples)],\n",
    "        'Last_Name': [name_gen.last_name() for _ in range(num_samples)]\n",
    "    })\n",
    "    height_df = pd.DataFrame({'Height': heights})\n",
    "    basic_df = pd.concat([name_df, height_df], axis=1)\n",
    "\n",
    "    # Define country list and correlation rules\n",
    "    countries = [\"USA\", \"Canada\", \"Germany\", \"France\", \"Italy\", \"China\", \"Brazil\", \"Australia\", \"Japan\", \"UK\", \"Sweden\", \"Norway\", \"Denmark\", \"Finland\"]\n",
    "\n",
    "    # Ice cream preferences (default: random choice)\n",
    "    ice_creams = [\"Vanilla\", \"Chocolate\", \"Strawberry\", \"Mint\", \"Pistachio\", \"Stracciatella\"]\n",
    "\n",
    "    # Generate data\n",
    "    data = []\n",
    "    for i in range(num_samples):\n",
    "        person = {}\n",
    "\n",
    "        # Assign country\n",
    "        person[\"Country of Origin\"] = random.choice(countries)\n",
    "\n",
    "        # Assign favorite ice cream with correlation (Italy → Stracciatella preference)\n",
    "        if person[\"Country of Origin\"] == \"Italy\":\n",
    "            person[\"Favorite Ice Cream\"] = np.random.choice(ice_creams, p=[0.1, 0.1, 0.1, 0.1, 0.2, 0.4])\n",
    "        else:\n",
    "            person[\"Favorite Ice Cream\"] = random.choice(ice_creams)\n",
    "\n",
    "        # Assign liking for liquorice (Nordic countries → Higher probability)\n",
    "        if person[\"Country of Origin\"] in [\"Sweden\", \"Norway\", \"Denmark\", \"Finland\"]:\n",
    "            person[\"Likes Liquorice\"] = np.random.choice([1, 0], p=[0.9, 0.1])  # 70% chance for Nordic countries\n",
    "        else:\n",
    "            person[\"Likes Liquorice\"] = np.random.choice([1, 0], p=[0.2, 0.8])  # 20% for others\n",
    "\n",
    "        # Assign number of times visited Italy (Random integer, but higher if from Europe)\n",
    "        if person[\"Country of Origin\"] in [\"Germany\", \"France\", \"UK\", \"Sweden\", \"Norway\", \"Denmark\", \"Finland\", \"Italy\"]:\n",
    "            person[\"Times Visited Italy\"] = np.random.poisson(2)  # Higher average visits\n",
    "        else:\n",
    "            person[\"Times Visited Italy\"] = np.random.poisson(0.5)  # Lower average visits\n",
    "\n",
    "        # First time in London (UK residents more likely to say yes)\n",
    "        person[\"First Time in London\"] = 1 if person[\"Country of Origin\"] == \"UK\" else np.random.choice([1, 0], p=[0.2, 0.8])\n",
    "\n",
    "        # Number of steps per day (Normal distribution with realistic values)\n",
    "        person[\"Steps per Day\"] = max(1000, int(np.random.normal(8000, 3000)))  # Avoids negative steps\n",
    "\n",
    "        data.append(person)\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    full_df = pd.concat([basic_df, df], axis=1, ignore_index=True)\n",
    "    \n",
    "    if liquorice == 0:\n",
    "        # Sample row: UK resident who does NOT like liquorice\n",
    "        indiv = [\n",
    "            \"James\", \"Smith\", round(random.gauss(175, 10), 2), \"UK\", \"Strawberry\", 0, 2, 0, 7500\n",
    "        ]\n",
    "        indiv_df = pd.DataFrame([indiv], columns=full_df.columns)\n",
    "    if liquorice == 1:\n",
    "        # Sample row: Sweden resident who LIKES liquorice\n",
    "        indiv = [\n",
    "            \"Lars\", \"Andersson\", round(random.gauss(185, 10), 2), \"Sweden\", \"Chocolate\", 1, 3, 0, 9200 \n",
    "        ]\n",
    "        indiv_df = pd.DataFrame([indiv], columns=full_df.columns)\n",
    "    full_df = pd.concat([full_df, indiv_df], ignore_index=True)\n",
    "    full_df.columns = [\"First Name\", \"Last Name\", \"Height\", \"Nationality\", \"Favorite Icecream\", \"Like Liquorice\", \"Times Been to Italy\", \"First Time London\", \"Steps per Day\"]\n",
    "    print(full_df)\n",
    "    # Save to CSV (optional)\n",
    "    full_df.to_csv(f\"sample_data_{liquorice}.csv\", index=False)\n",
    "\n",
    "def synthesize_no_bin(real_data, eps):    \n",
    "    # instantiate and fit synthesizer\n",
    "    pb = PrivBayes(epsilon=eps, verbose=False)\n",
    "    pb.fit(real_data)\n",
    "\n",
    "    # Synthesize data\n",
    "    gen_data  = pb.sample()\n",
    "\n",
    "    # Save to csv file\n",
    "    result = pd.DataFrame(gen_data.values, columns=gen_data.columns, index=range(real_data.shape[0]))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def synthesize_bin(real_data, eps):\n",
    "    \n",
    "    describer = DataDescriber()\n",
    "    timestamp = datetime.now().timestamp()\n",
    "    real_data.to_csv(f'{timestamp}.csv', index=False)\n",
    "    describer.describe_dataset_in_correlated_attribute_mode(dataset_file=f'{timestamp}.csv', \n",
    "                                                            epsilon=eps, \n",
    "                                                            k=2,\n",
    "                                                            attribute_to_is_candidate_key={\"First Name\": False, \"Last Name\": False, \"Height\": False, \"Nationality\": False, \"Favorite Icecream\": False, \"Like Liquorice\": False, \"Times Been to Italy\": False, \"First Time London\": False, \"Steps per Day\": False},\n",
    "                                                            attribute_to_datatype={\"First Name\": \"String\", \"Last Name\": \"String\", \"Height\": \"Float\", \"Nationality\": \"String\",\"Favorite Icecream\": \"String\",\"Like Liquorice\": \"Integer\",\"Times Been to Italy\": \"Integer\", \"First Time London\": \"Integer\",\"Steps per Day\": \"Integer\"},\n",
    "                                                            attribute_to_is_categorical={'First Name': True, 'Last Name': True, 'Height': False, \"Nationality\": True, \"Favorite Icecream\": True,\"Like Liquorice\": True,\"Times Been to Italy\": True, \"First Time London\": True,\"Steps per Day\": False},\n",
    "                                                            )\n",
    "    description = f'{timestamp}.json'\n",
    "    syn_path = f'syn_{timestamp}.csv'\n",
    "    describer.save_dataset_description_to_file(description)\n",
    "    generator = DataGenerator()\n",
    "    generator.generate_dataset_in_correlated_attribute_mode(n=len(real_data), description_file=description, seed=timestamp)\n",
    "    generator.save_synthetic_data(syn_path)\n",
    "    result = pd.read_csv(syn_path, index_col=False).round(2)\n",
    "    os.remove(f'{timestamp}.csv')\n",
    "    os.remove(f'{timestamp}.json')\n",
    "    os.remove(f'syn_{timestamp}.csv')\n",
    "    \n",
    "    return result\n",
    "\n",
    "    \n",
    "#generate_real_data(1499, 1)\n",
    "#generate_real_data(1499, 0)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    eps_list = [0.02, 0.05, 0.1, 0.2, 0.5, 1, 2.5, 5]\n",
    "    for liquorice in [0,1]:\n",
    "        real_dir = f'sample_data_{liquorice}.csv'\n",
    "        real_data = pd.read_csv(real_dir, index_col=False)\n",
    "        for eps in eps_list:\n",
    "            #synthesize_no_bin(real_data, eps).to_csv(f\"demo_syn/syn_bin_{liquorice}_{eps}.csv\")\n",
    "            synthesize_bin(real_data, eps).to_csv(f\"demo_syn_new/syn_no_{liquorice}_{eps}.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list = [0.02, 0.05, 0.1, 0.2, 0.5, 1, 2.5, 5]\n",
    "for liquorice in [0,1]:\n",
    "    for eps in eps_list:\n",
    "        df1 = pd.read_csv(f\"metric_results/syn_no_{liquorice}_{eps}.csv\")\n",
    "        df2 = pd.read_csv(f\"metric_full/syn_no_{liquorice}_{eps}.csv\")\n",
    "        df1.loc[df1[\"Metric\"] == \"Hitting Rate\", \"Result\"] = df2.loc[df2[\"Metric\"] == \"Hitting Rate\", \"Result\"].values[0]\n",
    "        df1.to_csv(f\"metric_results/syn_no_{liquorice}_{eps}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
